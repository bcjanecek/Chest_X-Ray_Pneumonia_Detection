{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T15:26:53.677029Z",
     "start_time": "2020-05-15T15:26:53.663063Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bjane\\Miniconda3\\envs\\learn-env\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:160: UserWarning: pylab import has clobbered these variables: ['imread']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.image import imread\n",
    "import matplotlib.ticker as mtick\n",
    "%matplotlib inline\n",
    "%pylab inline\n",
    "import seaborn as sns\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization, GaussianNoise\n",
    "from keras.metrics import Precision, Recall\n",
    "from keras.applications import Xception, VGG16\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras import optimizers\n",
    "from keras.models import load_model\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T02:26:03.066695Z",
     "start_time": "2020-05-15T02:26:03.063724Z"
    }
   },
   "outputs": [],
   "source": [
    "# define path to save model\n",
    "model_path = './fully_trained_VGG_best_model.h5'\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_accuracy', \n",
    "                           patience=10,\n",
    "                           mode='max',\n",
    "                           verbose=1),\n",
    "             ModelCheckpoint(model_path,\n",
    "                             monitor='val_accuracy', \n",
    "                             save_best_only=True, \n",
    "                             mode='max',\n",
    "                             verbose=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T15:25:03.924146Z",
     "start_time": "2020-05-15T15:25:03.915150Z"
    }
   },
   "outputs": [],
   "source": [
    "# define model evaluation\n",
    "def model_evaluation(history, p_r_iteration=2):\n",
    "\n",
    "    # set context for plots\n",
    "    sns.set_style('darkgrid') \n",
    "    sns.set_context('talk') \n",
    "    \n",
    "    # define number of epochs\n",
    "    epochs = range(1, len(history.history['accuracy'])+1)\n",
    "    \n",
    "    # plot accuracy\n",
    "    plt.figure(figsize=(15,8))\n",
    "    pyplot.title(\"Accuracy\") \n",
    "    ax = plt.plot(epochs, history.history['accuracy'], color='blue', label='Train Data') \n",
    "    ax = plt.plot(epochs, history.history['val_accuracy'], color='orange', label='Validation Data') \n",
    "    plt.xticks(np.arange(min(epochs), max(epochs)+1, 5))\n",
    "    plt.legend()\n",
    "    \n",
    "    # plot recall\n",
    "    plt.figure(figsize=(15,8))\n",
    "    pyplot.title(\"Precision\") \n",
    "    plt.plot(epochs, history.history['recall_{}'.format(p_r_iteration)], color='blue', label='Train Data') \n",
    "    plt.plot(epochs, history.history['val_recall_{}'.format(p_r_iteration)], color='orange', label='Validation Data') \n",
    "    plt.xticks(np.arange(min(epochs), max(epochs)+1, 5))\n",
    "    plt.legend()\n",
    "    \n",
    "    # plot precision\n",
    "    plt.figure(figsize=(15,8))\n",
    "    pyplot.title(\"Recall\") \n",
    "    plt.plot(epochs, history.history['precision_{}'.format(p_r_iteration)], color='blue', label='Train Data') \n",
    "    plt.plot(epochs, history.history['val_precision_{}'.format(p_r_iteration)], color='orange', label='Validation Data') \n",
    "    plt.xticks(np.arange(min(epochs), max(epochs)+1, 5))\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T02:26:06.803933Z",
     "start_time": "2020-05-15T02:26:06.798933Z"
    }
   },
   "outputs": [],
   "source": [
    "# directory path\n",
    "train_data_dir = 'chest_xray/train'\n",
    "test_data_dir = 'chest_xray/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T02:26:08.241931Z",
     "start_time": "2020-05-15T02:26:07.686931Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4695 images belonging to 2 classes.\n",
      "Found 521 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# create new instances for VGG16 model\n",
    "generator_vgg16 = ImageDataGenerator(rescale=1.0/255.0,\n",
    "                                     validation_split=0.10,\n",
    "                                     horizontal_flip=True)\n",
    "\n",
    "generator_vgg16_test = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "# specify feature wise centering from ImageNet dataset\n",
    "#generator_vgg16.mean = [123.68, 116.779, 103.939] \n",
    "#generator_vgg16_test.mean = [123.68, 116.779, 103.939] \n",
    "                                         \n",
    "# Get all the data in the directory chest_xrays/train and resize\n",
    "train_gen_vgg16 = generator_vgg16.flow_from_directory(\n",
    "        train_data_dir, \n",
    "        target_size=(112, 112), \n",
    "        class_mode='binary',\n",
    "        batch_size=64,\n",
    "        color_mode='rgb',\n",
    "        subset='training')\n",
    "\n",
    "# create a validation dataset\n",
    "val_gen_vgg16 = generator_vgg16.flow_from_directory(\n",
    "        train_data_dir, \n",
    "        target_size=(112, 112), \n",
    "        class_mode='binary',\n",
    "        batch_size=64,\n",
    "        color_mode='rgb',\n",
    "        subset='validation')\n",
    "\n",
    "# Get all the data in the directory chest_xrays/test and resize\n",
    "test_gen_vgg16 = generator_vgg16_test.flow_from_directory(\n",
    "        test_data_dir, \n",
    "        target_size=(112, 112), \n",
    "        class_mode='binary',\n",
    "        batch_size=64, \n",
    "        color_mode='rgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T02:26:21.848846Z",
     "start_time": "2020-05-15T02:26:21.839855Z"
    }
   },
   "outputs": [],
   "source": [
    "# define VGG16 model\n",
    "def create_VGG16_model(classification_threshold=0.5):\n",
    "\n",
    "    # load VGG16 model\n",
    "    cnn_base = VGG16(include_top=False, input_shape=(112, 112, 3))\n",
    "    \n",
    "    # mark VGG16 model layers as untrainable\n",
    "    #cnn_base.trainable = False\n",
    "    \n",
    "    # initialize model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # add CNN base\n",
    "    model.add(cnn_base)\n",
    "    \n",
    "    # add flattening layer\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # add dense layer\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    \n",
    "    # add dropout layer\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    # add second dense layer\n",
    "    model.add(Dense(64, activation='relu', kernel_initializer='he_uniform'))\n",
    "\n",
    "    # add output layer\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_initializer='he_uniform'))\n",
    "\n",
    "    # custom decaying optimizer\n",
    "    \n",
    "    #optimizer = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "    opt = optimizers.SGD(lr=0.001, momentum=0.9)\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', Precision(classification_threshold), \n",
    "                                                                         Recall(classification_threshold)])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T02:26:26.615169Z",
     "start_time": "2020-05-15T02:26:25.767077Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\bjane\\Miniconda3\\envs\\learn-env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\bjane\\Miniconda3\\envs\\learn-env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3172: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# create VGG16 model\n",
    "VGG16_model = create_VGG16_model(classification_threshold=0.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T07:09:24.509025Z",
     "start_time": "2020-05-15T02:27:48.406384Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\bjane\\Miniconda3\\envs\\learn-env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/50\n",
      "74/74 [==============================] - 830s 11s/step - loss: 0.6759 - accuracy: 0.6988 - precision_1: 0.7494 - recall_1: 0.8933 - val_loss: 0.7009 - val_accuracy: 0.6250 - val_precision_1: 0.6250 - val_recall_1: 1.0000\n",
      "Epoch 2/50\n",
      "74/74 [==============================] - 873s 12s/step - loss: 0.5502 - accuracy: 0.7450 - precision_1: 0.7610 - recall_1: 0.9576 - val_loss: 0.4469 - val_accuracy: 0.7740 - val_precision_1: 0.8120 - val_recall_1: 0.8308\n",
      "Epoch 3/50\n",
      "74/74 [==============================] - 865s 12s/step - loss: 0.2928 - accuracy: 0.8628 - precision_1: 0.9063 - recall_1: 0.9094 - val_loss: 0.6660 - val_accuracy: 0.7724 - val_precision_1: 0.7551 - val_recall_1: 0.9410\n",
      "Epoch 4/50\n",
      "74/74 [==============================] - 858s 12s/step - loss: 0.2006 - accuracy: 0.9137 - precision_1: 0.9403 - recall_1: 0.9438 - val_loss: 0.7477 - val_accuracy: 0.7308 - val_precision_1: 0.7071 - val_recall_1: 0.9718\n",
      "Epoch 5/50\n",
      "74/74 [==============================] - 856s 12s/step - loss: 0.1962 - accuracy: 0.9248 - precision_1: 0.9475 - recall_1: 0.9515 - val_loss: 0.3644 - val_accuracy: 0.7869 - val_precision_1: 0.7728 - val_recall_1: 0.9333\n",
      "Epoch 6/50\n",
      "74/74 [==============================] - 854s 12s/step - loss: 0.1456 - accuracy: 0.9450 - precision_1: 0.9614 - recall_1: 0.9647 - val_loss: 0.4940 - val_accuracy: 0.7917 - val_precision_1: 0.7743 - val_recall_1: 0.9410\n",
      "Epoch 7/50\n",
      "74/74 [==============================] - 862s 12s/step - loss: 0.1429 - accuracy: 0.9455 - precision_1: 0.9607 - recall_1: 0.9662 - val_loss: 1.3863 - val_accuracy: 0.7019 - val_precision_1: 0.6789 - val_recall_1: 0.9923\n",
      "Epoch 8/50\n",
      "74/74 [==============================] - 856s 12s/step - loss: 0.1300 - accuracy: 0.9508 - precision_1: 0.9638 - recall_1: 0.9702 - val_loss: 0.4882 - val_accuracy: 0.7772 - val_precision_1: 0.7409 - val_recall_1: 0.9897\n",
      "Epoch 9/50\n",
      "74/74 [==============================] - 847s 11s/step - loss: 0.1172 - accuracy: 0.9587 - precision_1: 0.9716 - recall_1: 0.9728 - val_loss: 1.5397 - val_accuracy: 0.7516 - val_precision_1: 0.7308 - val_recall_1: 0.9538\n",
      "Epoch 10/50\n",
      "74/74 [==============================] - 850s 11s/step - loss: 0.1087 - accuracy: 0.9612 - precision_1: 0.9728 - recall_1: 0.9751 - val_loss: 0.4915 - val_accuracy: 0.8045 - val_precision_1: 0.7803 - val_recall_1: 0.9564\n",
      "Epoch 11/50\n",
      "74/74 [==============================] - 843s 11s/step - loss: 0.0881 - accuracy: 0.9666 - precision_1: 0.9765 - recall_1: 0.9785 - val_loss: 7.6383 - val_accuracy: 0.7500 - val_precision_1: 0.7208 - val_recall_1: 0.9795\n",
      "Epoch 12/50\n",
      "74/74 [==============================] - 839s 11s/step - loss: 0.1069 - accuracy: 0.9604 - precision_1: 0.9736 - recall_1: 0.9731 - val_loss: 2.3919 - val_accuracy: 0.6955 - val_precision_1: 0.6724 - val_recall_1: 1.0000\n",
      "Epoch 13/50\n",
      "74/74 [==============================] - 837s 11s/step - loss: 0.0879 - accuracy: 0.9681 - precision_1: 0.9774 - recall_1: 0.9796 - val_loss: 0.7511 - val_accuracy: 0.7388 - val_precision_1: 0.7083 - val_recall_1: 0.9897\n",
      "Epoch 14/50\n",
      "74/74 [==============================] - 833s 11s/step - loss: 0.0735 - accuracy: 0.9708 - precision_1: 0.9797 - recall_1: 0.9811 - val_loss: 1.6692 - val_accuracy: 0.7500 - val_precision_1: 0.7159 - val_recall_1: 0.9949\n",
      "Epoch 15/50\n",
      "74/74 [==============================] - 833s 11s/step - loss: 0.0759 - accuracy: 0.9708 - precision_1: 0.9794 - recall_1: 0.9814 - val_loss: 1.3350 - val_accuracy: 0.7356 - val_precision_1: 0.7057 - val_recall_1: 0.9897\n",
      "Epoch 16/50\n",
      "74/74 [==============================] - 831s 11s/step - loss: 0.0674 - accuracy: 0.9757 - precision_1: 0.9842 - recall_1: 0.9831 - val_loss: 0.3366 - val_accuracy: 0.7821 - val_precision_1: 0.7452 - val_recall_1: 0.9897\n",
      "Epoch 17/50\n",
      "74/74 [==============================] - 827s 11s/step - loss: 0.0639 - accuracy: 0.9742 - precision_1: 0.9833 - recall_1: 0.9819 - val_loss: 1.6049 - val_accuracy: 0.7292 - val_precision_1: 0.6984 - val_recall_1: 0.9974\n",
      "Epoch 18/50\n",
      "74/74 [==============================] - 835s 11s/step - loss: 0.0553 - accuracy: 0.9787 - precision_1: 0.9854 - recall_1: 0.9860 - val_loss: 1.7690 - val_accuracy: 0.8045 - val_precision_1: 0.7669 - val_recall_1: 0.9872\n",
      "Epoch 19/50\n",
      "74/74 [==============================] - 835s 11s/step - loss: 0.0725 - accuracy: 0.9744 - precision_1: 0.9839 - recall_1: 0.9817 - val_loss: 1.3749 - val_accuracy: 0.7452 - val_precision_1: 0.7127 - val_recall_1: 0.9923\n",
      "Epoch 20/50\n",
      "74/74 [==============================] - 827s 11s/step - loss: 0.0534 - accuracy: 0.9800 - precision_1: 0.9865 - recall_1: 0.9865 - val_loss: 2.9617 - val_accuracy: 0.7292 - val_precision_1: 0.6984 - val_recall_1: 0.9974\n",
      "Epoch 00020: early stopping\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "history_VGG16 = VGG16_model.fit_generator(train_gen_vgg16, steps_per_epoch=len(train_gen_vgg16), \n",
    "                                         epochs=50, validation_data=val_gen_vgg16, validation_steps=len(val_gen_vgg16),\n",
    "                                         callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T00:50:50.621446Z",
     "start_time": "2020-05-15T00:48:35.176440Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Accuracy: 77.56410241127014%\n",
      "Test Set Precision: 73.94636273384094%\n",
      "Test Set Recall: 98.97435903549194%\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "\n",
    "VGG16_test_accuracy = VGG16_model.evaluate_generator(test_gen_vgg16, steps=len(test_gen_vgg16))[1]\n",
    "VGG16_test_precision = VGG16_model.evaluate_generator(test_gen_vgg16, steps=len(test_gen_vgg16))[2]\n",
    "VGG16_test_recall = VGG16_model.evaluate_generator(test_gen_vgg16, steps=len(test_gen_vgg16))[3]\n",
    "\n",
    "print(\"Test Set Accuracy: {}%\".format(VGG16_test_accuracy*100))\n",
    "print(\"Test Set Precision: {}%\".format(VGG16_test_precision*100))\n",
    "print(\"Test Set Recall: {}%\".format(VGG16_test_recall*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T00:55:58.443327Z",
     "start_time": "2020-05-15T00:54:58.505951Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[ 33 201]\n",
      " [ 58 332]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.14      0.20       234\n",
      "           1       0.62      0.85      0.72       390\n",
      "\n",
      "    accuracy                           0.58       624\n",
      "   macro avg       0.49      0.50      0.46       624\n",
      "weighted avg       0.53      0.58      0.53       624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# plot confusion matrix for test set\n",
    "Y_pred_vgg16 = VGG16_model.predict_generator(test_gen_vgg16, 10, workers=0)\n",
    "y_pred_vgg16 = np.where(Y_pred_vgg16 > 0.40, 1, 0)\n",
    "print('Confusion Matrix')\n",
    "cm = metrics.confusion_matrix(test_gen_vgg16.classes, y_pred_vgg16)\n",
    "print(cm)\n",
    "print('Classification Report')\n",
    "print(metrics.classification_report(test_gen_vgg16.classes, y_pred_vgg16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
